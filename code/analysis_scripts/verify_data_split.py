#!/usr/bin/env python3
"""
KRITISCHE VERIFIKATION: √úberpr√ºft, ob Train/Val/Test wirklich getrennt sind.

Checks:
1. Keine √úberlappung zwischen Train/Val/Test (Data Leakage)
2. Stratified Split wurde korrekt angewendet
3. Reproduzierbarkeit mit festem Seed
"""

import os
import sys
import json
import numpy as np
from pathlib import Path

# Add project root to path
project_root = Path(__file__).parent.parent.parent
sys.path.append(str(project_root / "code"))

from core.data import SeverstalFullImageDataset, StratifiedSplitter


def verify_no_overlap(train_names, val_names, test_names):
    """√úberpr√ºft, dass Train/Val/Test keine gemeinsamen Bilder haben."""
    print("\nüîç KRITISCHER CHECK: Overlap-Verifikation")
    print("=" * 60)
    
    train_set = set(train_names)
    val_set = set(val_names)
    test_set = set(test_names)
    
    # Check for overlaps
    train_val_overlap = train_set & val_set
    train_test_overlap = train_set & test_set
    val_test_overlap = val_set & test_set
    
    print(f"Train samples: {len(train_set)}")
    print(f"Val samples:   {len(val_set)}")
    print(f"Test samples:  {len(test_set)}")
    print(f"Total unique:  {len(train_set | val_set | test_set)}")
    
    if train_val_overlap:
        print(f"\nüî¥ CRITICAL ERROR: Train/Val overlap detected!")
        print(f"   Overlapping samples: {len(train_val_overlap)}")
        print(f"   Examples: {list(train_val_overlap)[:5]}")
        return False
    
    if train_test_overlap:
        print(f"\nüî¥ CRITICAL ERROR: Train/Test overlap detected!")
        print(f"   Overlapping samples: {len(train_test_overlap)}")
        print(f"   Examples: {list(train_test_overlap)[:5]}")
        return False
    
    if val_test_overlap:
        print(f"\nüî¥ CRITICAL ERROR: Val/Test overlap detected!")
        print(f"   Overlapping samples: {len(val_test_overlap)}")
        print(f"   Examples: {list(val_test_overlap)[:5]}")
        return False
    
    print("\n‚úÖ NO OVERLAP DETECTED - Splits are completely disjoint!")
    return True


def verify_stratified_split(all_labels, train_idx, val_idx, test_idx):
    """√úberpr√ºft, dass Klassenverteilung erhalten bleibt."""
    print("\nüìä STRATIFIED SPLIT Verifikation")
    print("=" * 60)
    
    # Calculate class distributions
    train_labels = all_labels[train_idx]
    val_labels = all_labels[val_idx]
    test_labels = all_labels[test_idx]
    
    class_names = ['no_defect', 'defect_1', 'defect_2', 'defect_3', 'defect_4']
    
    print(f"\n{'Class':<12} | {'All':>8} | {'Train':>8} | {'Val':>8} | {'Test':>8} | {'Max Œî':>8}")
    print("-" * 70)
    
    max_deviation = 0
    
    for i, class_name in enumerate(class_names):
        all_freq = all_labels[:, i].mean()
        train_freq = train_labels[:, i].mean()
        val_freq = val_labels[:, i].mean()
        test_freq = test_labels[:, i].mean()
        
        # Calculate max deviation from overall distribution
        deviation = max(
            abs(train_freq - all_freq),
            abs(val_freq - all_freq),
            abs(test_freq - all_freq)
        )
        max_deviation = max(max_deviation, deviation)
        
        status = "‚úÖ" if deviation < 0.05 else "‚ö†Ô∏è" if deviation < 0.10 else "üî¥"
        
        print(f"{class_name:<12} | {all_freq:>7.1%} | {train_freq:>7.1%} | {val_freq:>7.1%} | {test_freq:>7.1%} | {deviation:>7.1%} {status}")
    
    print(f"\nMaximale Abweichung: {max_deviation:.1%}")
    
    if max_deviation < 0.05:
        print("‚úÖ Excellent stratification - distributions well preserved!")
    elif max_deviation < 0.10:
        print("‚ö†Ô∏è  Acceptable stratification - minor deviations")
    else:
        print("üî¥ Poor stratification - significant distribution shift!")
    
    return max_deviation < 0.10


def verify_reproducibility(all_labels, seed=42):
    """√úberpr√ºft, dass der Split mit festem Seed reproduzierbar ist."""
    print("\nüîÅ REPRODUCIBILITY Check")
    print("=" * 60)
    
    splitter1 = StratifiedSplitter(random_state=seed)
    train_idx1, val_idx1, test_idx1 = splitter1.split(all_labels, (0.7, 0.15, 0.15))
    
    splitter2 = StratifiedSplitter(random_state=seed)
    train_idx2, val_idx2, test_idx2 = splitter2.split(all_labels, (0.7, 0.15, 0.15))
    
    train_match = np.array_equal(train_idx1, train_idx2)
    val_match = np.array_equal(val_idx1, val_idx2)
    test_match = np.array_equal(test_idx2, test_idx2)
    
    print(f"Train indices match: {train_match}")
    print(f"Val indices match:   {val_match}")
    print(f"Test indices match:  {test_match}")
    
    if train_match and val_match and test_match:
        print("\n‚úÖ Split is REPRODUCIBLE with fixed seed!")
        return True
    else:
        print("\nüî¥ Split is NOT reproducible - this is a problem!")
        return False


def main():
    """Main verification function"""
    print("üõ°Ô∏è  DATA SPLIT INTEGRITY VERIFICATION")
    print("=" * 60)
    print("√úberpr√ºft die Integrit√§t des Train/Val/Test Splits")
    print()
    
    # Load dataset
    img_dir = project_root / "data" / "images"
    ann_dir = project_root / "data" / "annotations"
    
    print(f"üìÇ Loading dataset from:")
    print(f"   Images: {img_dir}")
    print(f"   Annotations: {ann_dir}")
    
    # Get all image files
    import glob
    all_image_files = sorted([
        os.path.basename(f) for f in glob.glob(str(img_dir / "*.jpg"))
    ])
    
    print(f"   Found {len(all_image_files)} images")
    
    # Create dataset
    dataset = SeverstalFullImageDataset(
        img_dir=str(img_dir),
        ann_dir=str(ann_dir),
        image_names=all_image_files,
        transform=None,
        num_classes=5
    )
    
    print(f"\n‚úÖ Loaded {len(dataset.samples)} samples")
    
    # Extract labels and names
    all_labels = np.array([sample["label"] for sample in dataset.samples])
    all_image_names = np.array([sample["image_name"] for sample in dataset.samples])
    
    print(f"   Label matrix shape: {all_labels.shape}")
    
    # Perform split (same as in training)
    seed = 42
    splitter = StratifiedSplitter(random_state=seed)
    train_idx, val_idx, test_idx = splitter.split(all_labels, (0.7, 0.15, 0.15))
    
    train_names = all_image_names[train_idx].tolist()
    val_names = all_image_names[val_idx].tolist()
    test_names = all_image_names[test_idx].tolist()
    
    # Run verification checks
    print("\n" + "=" * 60)
    print("RUNNING VERIFICATION CHECKS...")
    print("=" * 60)
    
    check1 = verify_no_overlap(train_names, val_names, test_names)
    check2 = verify_stratified_split(all_labels, train_idx, val_idx, test_idx)
    check3 = verify_reproducibility(all_labels, seed)
    
    # Final verdict
    print("\n" + "=" * 60)
    print("üéØ FINAL VERDICT")
    print("=" * 60)
    
    checks = {
        "No data leakage (disjoint splits)": check1,
        "Stratified distribution preserved": check2,
        "Reproducible with fixed seed": check3
    }
    
    all_passed = all(checks.values())
    
    for check_name, passed in checks.items():
        status = "‚úÖ PASS" if passed else "üî¥ FAIL"
        print(f"{status}: {check_name}")
    
    print("\n" + "=" * 60)
    
    if all_passed:
        print("‚úÖ‚úÖ‚úÖ ALL CHECKS PASSED ‚úÖ‚úÖ‚úÖ")
        print("\nDein Data Split ist SAUBER und BELASTBAR!")
        print("Die F1 Scores von Val 0.9228 und Test 0.9144 sind valide!")
    else:
        print("üî¥üî¥üî¥ SOME CHECKS FAILED üî¥üî¥üî¥")
        print("\nEs gibt Probleme mit dem Data Split!")
        print("Die Ergebnisse sind m√∂glicherweise NICHT belastbar!")
    
    print("=" * 60)


if __name__ == "__main__":
    main()
